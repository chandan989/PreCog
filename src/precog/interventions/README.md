# Interventions Package

This package is responsible for the logic related to suggesting, managing, or implementing interventions based on the risk assessments (sentiment alerts, friction risks, misinformation alerts) provided by the PreCog application.

## `intervention_recommender.py`

This module contains the `InterventionRecommender` class, which is designed to suggest actionable interventions based on various alerts generated by the PreCog system. It can use predefined templates or leverage an LLM for more dynamic and context-aware suggestions.

Key functionalities include:

- **Initialization**: 
    - Can be initialized with an optional LLM client (`BaseLLMClient`). If an LLM client is provided and enabled, it can be used to generate intervention suggestions.
- **Alert Processing**: 
    - Takes lists of `SentimentAlert`, `FrictionRisk`, and `MisinformationAlert` objects as input.
    - Determines the `issue_type` (e.g., 'misinformation', 'civic_grievance', 'social_tension') based on the type and properties of each alert.
    - Extracts relevant `context` from each alert, such as location, narrative, issue details, and topic.
- **Intervention Templates**: 
    - Utilizes a predefined set of `INTERVENTION_TEMPLATES` categorized by issue type (misinformation, civic_grievance, social_tension) and timeframe (immediate, short_term, long_term).
    - These templates provide structured, placeholder-driven intervention suggestions (e.g., "Issue pre-bunking/debunking message on official channels regarding '{narrative}'.").
- **LLM-Powered Suggestions (Optional)**:
    - If `use_llm_for_suggestions` is true and an LLM client is available, the `_generate_llm_intervention_suggestion` method is called.
    - This method constructs a detailed prompt for the LLM, providing context about the issue type, details, location, narrative, and topic, asking for a specific and actionable intervention suggestion tailored to an Indian context.
    - It attempts to clean up the LLM's response to make it more direct.
    - If the LLM fails to generate a suggestion or is not used, the system falls back to using the predefined templates.
- **Recommendation Generation (`recommend_interventions` method)**:
    - Sorts all incoming alerts based on a custom priority: Misinformation > Friction Risk > Sentiment Alert, and then by severity/risk score within each type.
    - For each alert, it determines the issue type and context.
    - Generates intervention actions for 'immediate', 'short_term', and 'long_term' periods using either LLM-generated text (if enabled and successful) or template-based text.
    - Each `InterventionAction` object stores the description, priority (derived from alert severity), source alert ID, suggested by (template or LLM), and associated resources.
    - Identifies `priority_locations` based on the locations mentioned in the alerts.
    - Suggests `resource_allocation` by mapping intervention actions to predefined `RESOURCE_REQUIREMENTS` (e.g., communication_team, field_officers).
- **Output**: 
    - Returns a dictionary containing lists of `InterventionAction` objects categorized by timeframe (immediate_actions, short_term_actions, long_term_actions), a set of `priority_locations`, and a dictionary detailing `resource_allocation` needs.
- **Logging**: Includes logging for LLM interactions and potential errors.

This module plays a crucial role in translating analytical insights from the PreCog system into concrete, actionable steps for authorities or relevant stakeholders.